\name{getLikelihoods}
\alias{getLikelihoods}
\alias{getLikelihoods.Dirichlet}
\alias{getLikelihoods.NBboot}
\alias{getLikelihoods.Pois}
%- Also NEED an '\alias' for EACH other topic documented here.
\title{Finds posterior likelihoods for each count as belonging to some
  hypothesis.}
\description{
  These functions calculate posterior probabilities for each of the
  'counts' in the countDP object belonging to each of the groups
  specified. The choice of function depends on the prior belief about
  the underlying distribution of the data. It is essential that the
  method used for calculating priors matches the method used for
  calculating the posterior probabilites.

  For a comparison of the methods, see Hardcastle & Kelly, 2009.
}
\usage{
getLikelihoods(cD, prs, estimatePriors = TRUE, subset = NULL,
priorSubset = NULL, ..., cl)
getLikelihoods.Dirichlet(cD, prs, estimatePriors = TRUE, subset = NULL,
priorSubset = NULL, cl)
getLikelihoods.Pois(cD, prs, estimatePriors = TRUE, subset = NULL,
priorSubset = NULL, distpriors = FALSE, cl)
getLikelihoods.NBboot(cD, prs, estimatePriors = TRUE, subset = NULL,
priorSubset = NULL, bootStraps = 2, conv = 1e-4, nullData = FALSE, cl)
}
%- maybe also 'usage' for other objects documented here.
\arguments{
  \item{cD}{An object of type \code{\link{countData}}, or descending
    from this class.}
  \item{prs}{(Initial) prior probabilities for each of the groups in the
    'countDP' object. Should sum to 1, unless nullData is TRUE, in which
  case it should sum to less than 1.}
  \item{estimatePriors}{Should the prior probabilities on each of the
    groups be estimated by bootstrap from the data? Defaults to TRUE.}
  \item{subset}{Numeric vector giving the subset of counts for which
    posterior likelihoods should be estimated.}
  \item{priorSubset}{Numeric vector giving the subset of counts which may be
    used to estimate prior probabilities on each of the groups. See Details.}
  \item{distpriors}{Should the Poisson method use an empirically derived
    distribution on the prior parameters of the Poisson distribution, or
    use the mean of the maximum likelihood estimates (default).}
  \item{bootStraps}{How many iterations of bootstrapping should be used
    in the (re)estimation of priors in the negative binomial method.}
  \item{conv}{If not null, bootstrapping iterations will cease if the
    mean squared difference between posterior likelihoods of consecutive
    bootstraps drops below this value.}
  \item{nullData}{If TRUE, looks for segments or counts with no true
    expression. See Details.}
  \item{cl}{A SNOW cluster object.}
  \item{...}{Any additional information to be passed by the
    \code{'getLikelihoods'} wrapper function to the individual functions
    which calculate the likelihoods.}
}

\details{
  These functions estimate, under the assumption of various
  distributions, the (log) posterior likelihoods that each count belongs to a
  group defined by the \code{@group} slot of the \code{countData}
  object. The posterior likelihoods are stored on the natural log scale
  in the \code{@posteriors} slot of the \code{\link{countData}}
  object generated by this function. This is because the posterior
  likelihoods are calculated in this form, and ordering of the counts is
  better done on these log-likelihoods than on the likelihoods.
  
  If \code{'estimatePriors = TRUE'} then an attempt is made to
  re-estimate the prior likelihoods given in the \code{'prs'} variable
  by examining the posterior expectations for each group. This often works well
  (see Hardcastle & Kelly 2010 for details). However, if the data are
  sufficiently non-independent, this re-estimation may substantially
  mis-estimate the true priors. If it is possible to select a
  representative subset of the data by setting the variable
  \code{'subsetPriors'} that is sufficiently independent, then better
  estimates may be acquired. 
  
  The Dirichlet and Poisson methods produce almost identical
  results in simulation. The Negative Binomial method produces results
  with much lower false discovery rates, but takes considerably longer
  to run. The quality of the results of the Negative Binomial is further
  improved by increasing the amount of bootstrapping. However, this
  further increases the run time.
  
  Filtering the data may be extremely advantageous in reducing run
  time. This can be done by passing a numeric vector to 'subset'
  defining a subset of the data for which posterior likelihoods are
  required.

  If 'nullData = TRUE', the algorithm attempts to find those counts or
  segments that have no true expression in all samples. This means that
  there is another, implied group where all samples are equal. The prior
  likelihoods given in the 'prs' object must thus sum to less than 1,
  with the residual going to this group.
  
  See Hardcastle & Kelly (2010) for a full comparison of the methods.

  A 'cluster' object is strongly recommended in order to parallelise
  the estimation of posterior likelihoods, particularly for the
  negative binomial method. However, passing NULL to the \code{cl}
  variable will allow the functions to run in non-parallel mode.

  The \code{'getLikelihoods'} function will infer the correct
  distribution to use from the information stored in the
  \code{'@priors'} slot of the \code{\link{countData}} object
  \code{'sD'} and call the appropriate function.
}
\value{
  A \code{\link{countData}} object.
}
\references{Hardcastle T.J., and Kelly, K (2010). Identifying Patterns
  of Differential Expression in Count Data. In submission.}
\author{Thomas J. Hardcastle}


\seealso{\code{\link{countData}}, \code{\link{getPriors}},
  \code{\link{topCounts}}, \code{\link{getTPs}}}
\examples{

library(baySeq)

# See vignette for more examples.

# Create a {countData} object and estimate priors for the
# Poisson methods.
data(simCount)
data(libsizes)
groups <- list(c(1,1,1,1,1,1,1,1,1,1), c(1,1,1,1,1,2,2,2,2,2))
CD <- new("countData", data = simCount, libsizes = libsizes, groups = groups)
CDP.Poi <- getPriors.Pois(CD, samplesize = 20,
takemean = TRUE, cl = NULL)

# Get likelihoods for data with Poisson method
CDPost.Poi <- getLikelihoods.Pois(CDP.Poi, prs = c(0.5, 0.5),
estimatePriors = TRUE, cl = NULL)


# Alternatively, get priors for negative binomial method
CDP.NBML <- getPriors.NB(CD, samplesize = 10^5, estimation = "ML", cl = NULL)

# Get likelihoods for data with negative binomial method with bootstrapping

CDPost.NBML <- getLikelihoods.NBboot(CDP.NBML, prs = c(0.5, 0.5),
estimatePriors = TRUE, bootStraps = 2, cl = NULL)

# Alternatively, if we have the 'snow' package installed we
# can parallelise the functions. This will usually (not always) offer
# significant performance gain.

\dontrun{

library(snow)
cl <- makeCluster(4, 'SOCK')

CDP.NBML <- getPriors.NB(CD, samplesize = 10^5, estimation = "ML", cl = cl)
CDPost.NBML <- getLikelihoods.NBboot(CDP.NBML, prs = c(0.5, 0.5), 
estimatePriors = TRUE, bootStraps = 2, cl = cl)
}


}

\keyword{distribution}
\keyword{models}
